import streamlit as st
import google.generativeai as genai
from dotenv import load_dotenv
import firebase_admin
from firebase_admin import credentials, firestore
import os
import json

# Cargar credenciales desde Streamlit Secrets
firebase_config = st.secrets["FIREBASE"] 
cred = credentials.Certificate(json.loads(str(st.secrets["FIREBASE"])))

if not firebase_admin._apps:
    firebase_admin.initialize_app(cred)

db = firestore.client()

st.set_page_config(page_title="SmartSupport AI - Aritti", page_icon="üõçÔ∏è", layout="centered")

# Cargar variables de entorno
load_dotenv()

# Configurar la API de Gemini
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
if not GEMINI_API_KEY:
    st.error("‚ùå No se encontr√≥ la API Key. Verifica tu archivo .env.")
    st.stop()

genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel("gemini-1.5-pro")

# Configurar Firebase
firebase_credentials_path = os.getenv("FIREBASE_CREDENTIALS")
cred = credentials.Certificate(firebase_credentials_path)
if not firebase_admin._apps:
    firebase_admin.initialize_app(cred)
db = firestore.client()

# Obtener productos desde Firebase
@st.cache_data
def obtener_productos():
    productos_ref = db.collection("productosRopa")
    docs = productos_ref.stream()
    return [doc.to_dict() for doc in docs]

productos = obtener_productos()

# Generar contexto detallado de los productos
productos_texto = "\n".join([
    f"{p['title']} - {p['price']} - Stock: {p.get('stock', 'N/A')} - Categor√≠a: {p.get('category', 'N/A')} - "
    f"Color: {p.get('color', 'N/A')} - Material: {p.get('fabric', 'N/A')} - Talles: {', '.join(p.get('size', []))}"
    for p in productos
])

# # Funci√≥n para verificar stock
# def obtener_stock(producto_buscado):
#     productos_ref = db.collection("productosRopa")  # Aseg√∫rate de que la colecci√≥n es la correcta
#     query = productos_ref.where("title", "==", producto_buscado).stream()
    
#     stock_total = sum([int(doc.to_dict().get("stock", 0)) for doc in query])  # Convertir stock a entero
#     return stock_total

# Prompt inicial mejorado
prompt_inicial = f"""
Eres un asistente virtual exclusivo de **Aritti**, una tienda de ropa online. 
Tu objetivo es responder preguntas de clientes sobre:

- Disponibilidad de productos y stock.
- Precios y caracter√≠sticas de los art√≠culos.
- Tiempos de env√≠o y pol√≠tica de cambios.

Aqu√≠ tienes informaci√≥n actualizada de los productos en stock:

{productos_texto}

Si un cliente pregunta por un producto espec√≠fico, revisa la informaci√≥n proporcionada y responde con datos precisos. 
Si un producto est√° agotado, informa al cliente y sugiere opciones similares. No hagas preguntas innecesarias.
"""
# Funci√≥n para verificar stock
def obtener_stock(producto_buscado):
    productos_ref = db.collection("productosRopa")
    query = productos_ref.where("title", "==", producto_buscado).stream()
    stock_total = sum([int(doc.to_dict().get("stock", 0)) for doc in query])
    return stock_total

# Configurar la app en Streamlit
st.title("üõçÔ∏è SmartSupport AI para Aritti")
st.write("Bienvenido! Soy tu asistente virtual y estoy aqu√≠ para ayudarte con tus dudas sobre talles, disponibilidad de productos, env√≠os y cambios.")

# Mostrar productos disponibles
if st.checkbox("üì¶ Ver productos disponibles"):
    for producto in productos:
        st.write(f"**{producto['title']}** - {producto['price']} - Stock: {producto.get('stock', 'Desconocido')} - "
                f"Categor√≠a: {producto.get('category', 'N/A')} - Color: {producto.get('color', 'N/A')} - "
                f"Material: {producto.get('fabric', 'N/A')} - Talles: {', '.join(producto.get('size', []))}")

# üìå Preguntas Frecuentes
with st.expander("üìå Preguntas Frecuentes"):
    st.write("""
    **1Ô∏è‚É£ ¬øC√≥mo elegir el talle correcto?**  
    - Puedes revisar nuestra gu√≠a de talles en la web o preguntar en el chat.

    **2Ô∏è‚É£ ¬øCu√°nto tarda en llegar mi pedido?**  
    - Los env√≠os nacionales demoran entre 3 a 7 d√≠as h√°biles.

    **3Ô∏è‚É£ ¬øC√≥mo puedo hacer un cambio o devoluci√≥n?**  
    - Tienes hasta 30 d√≠as para cambiar un producto presentando tu factura.

    **4Ô∏è‚É£ ¬øHay descuentos o promociones activas?**  
    - ¬°S√≠! Pregunta en el chat para conocer nuestras ofertas actuales.
    """)

# Historial de chat (para mantener conversaciones previas)
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

for chat in st.session_state.chat_history:
    with st.chat_message(chat["role"]):
        st.markdown(chat["content"])

# Input del usuario
user_input = st.chat_input("Escribe tu mensaje aqu√≠...")

if user_input:
    with st.chat_message("user"):
        st.markdown(user_input)
    
    user_input_lower = user_input.lower()  # Asegurar que solo se define si hay entrada
    bot_response = ""

    # Si el usuario pregunta por stock, buscar en Firebase
    if "stock" in user_input_lower:
        producto_buscado = next((p["title"] for p in productos if p["title"].lower() in user_input_lower), None)
        if producto_buscado:
            stock_disponible = obtener_stock(producto_buscado)
            if stock_disponible > 0:
                bot_response = f"Actualmente, tenemos **{stock_disponible} unidades** del **{producto_buscado}** en stock."
            else:
                bot_response = f"Lo siento, el **{producto_buscado}** est√° agotado en este momento."
        else:
            bot_response = "No encontr√© ese producto en nuestro cat√°logo. Por favor, revisa nuestra web para m√°s detalles."

    # Si no es una pregunta sobre stock, procesar con IA
    else:
        try:
            mensaje_completo = f"{prompt_inicial}\n\nCliente: {user_input}\nAsistente:"
            response = model.generate_content(mensaje_completo)
            bot_response = response.text if hasattr(response, "text") else "No tengo una respuesta en este momento."
        except Exception as e:
            bot_response = f"‚ùå Error en la IA: {str(e)}"
    
    with st.chat_message("assistant"):
        st.markdown(bot_response)
    
    # Guardar en historial
    st.session_state.chat_history.append({"role": "user", "content": user_input})
    st.session_state.chat_history.append({"role": "assistant", "content": bot_response})
